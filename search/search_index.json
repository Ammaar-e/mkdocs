{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#icons-and-emojs","title":"Icons and Emojs","text":""},{"location":"AMRT/Azure/azure/","title":"Azure","text":"<p>We use Azure AD as our main user system. </p>"},{"location":"AMRT/Azure/azure/#azure-active-directory","title":"Azure Active Directory","text":"<p>We use Azure AD as our main user system. We have a E5 Licenses, and we use multiple enterpsrise applications.</p>"},{"location":"AMRT/Azure/azure/#service-accounts-test-ing-accounts","title":"Service Accounts &amp; Test ing Accounts","text":"<p>We use 2 main service accounts for connecting to services and IDP to apps that need an account to start a service.</p> <p>Service Accounts</p> <p>Interservices@amrt.xyz : Major SSO and Provisioning</p> <p>interservices2@amt.xyz : Smaller projects and apps</p> <p>We also use Testing Accounts to test services we want to use. They all go in the following order from 1-10testpurchase@amrt.xyz, (ex. 1testpurchase@amrt.xyz, 2testpurchase@amrt.xyz etc,.).</p>"},{"location":"AMRT/Domains/domains/","title":"Domains","text":"<p>We currently use the amrt.xyz</p>"},{"location":"AMRT/Domains/domains/#webistes","title":"Webistes","text":"<p>We currently have 1 website but plan on deploying our main website by the end of September.</p>"},{"location":"AMRT/Domains/domains/#docs","title":"Docs","text":"<p>We currently host our Documentation page at docs.amrt.xyz</p>"},{"location":"AMRT/Domains/domains/#website","title":"Website","text":"<p>We are planning to deploy ouur main website at amrt.xyz</p>"},{"location":"AMRT/Domains/domains/#emails-servers","title":"Emails Servers","text":"<p>We use the domains amrt.xyz and students.amrt.xyz.</p>"},{"location":"AMRT/Domains/domains/#amrtxyz","title":"Amrt.xyz","text":"<p>We use this email for all staff in the district and subs and cutodial. This domain is hosted on Azure Active Directory.</p>"},{"location":"AMRT/Domains/domains/#studentsamrtxyz","title":"Students.amrt.xyz","text":"<p>We use this email for all studnets in the district and as transfer accounts. This domain is hosted on Azure Active Directory.</p>"},{"location":"AMRT/How%20To/CloudflareSetup/","title":"How to login to Cloudflare","text":"<p>Please follow the video below:</p>"},{"location":"AMRT/IDP%27S/google/","title":"Google IDP","text":"<p>We use google as our IDP for staff and students to access Google Products. The following information below is how to set it up. The account connected to Google Worspace and the admin is interservices@amrt.xyz</p>"},{"location":"AMRT/IDP%27S/google/#lets-set-it-up","title":"Lets Set it up","text":""},{"location":"AMRT/IDP%27S/google/#this-document-shows-you-how-to-set-up-user-provisioning-and-single-sign-on-between-a-microsoft-azure-ad-tenant-and-your-cloud-identity-or-google-workspace-account-the-document-assumes-that-you-already-use-microsoft-office-365-or-azure-ad-in-your-organization-and-want-to-use-azure-ad-for-allowing-users-to-authenticate-with-google-cloud-azure-ad-itself-might-be-connected-to-an-on-premises-active-directory-and-might-use-ad-fs-federation-pass-through-authentication-or-password-hash-synchronization","title":"This document shows you how to set up user provisioning and single sign-on between a Microsoft Azure AD tenant and your Cloud Identity or Google Workspace account. The document assumes that you already use Microsoft Office 365 or Azure AD in your organization and want to use Azure AD for allowing users to authenticate with Google Cloud. Azure AD itself might be connected to an on-premises Active Directory and might use AD FS federation, pass-through authentication, or password hash synchronization.","text":"<p>Note: fees</p> <p>This article uses classic organizational SSO profiles to set up single sign-on. Using SAML profiles is currently incompatible with some Azure AD features, including Azure AD B2B. Objectives Set up Azure AD to automatically provision users and, optionally, groups to Cloud Identity or Google Workspace. Configure single sign-on to allow users to sign in to Google Cloud by using an Azure AD user account or a user that has been provisioned from Active Directory to Azure AD. Costs If you are using the free edition of Cloud Identity, setting up federation with Azure AD won't use any billable components of Google Cloud. Check the Azure AD pricing page for any fees that might apply to using Azure AD.</p>"},{"location":"AMRT/IDP%27S/google/#before-you-begin","title":"Before you begin","text":"<p>Make sure you understand the differences between connecting Google Cloud to Azure AD versus directly connecting Google Cloud to Active Directory. Decide how you want to map identities, groups, and domains between Azure AD and Cloud Identity or Google Workspace. Specifically, answer the following questions: Do you plan to use email addresses or User Principal Names (UPNs) as common identifiers for users? Do you plan to provision groups? If so, do you plan to map groups by email address or by name? Do you plan to provision all users to Google Cloud or only a select subset of users? Before connecting your production Azure AD tenant to Google Cloud, consider using an Azure AD test tenant for setting up and testing user provisioning. Sign up for Cloud Identity if you don't have an account already. If you're using the free edition of Cloud Identity and intend to provision more than 50 users, request an increase of the total number of free Cloud Identity users through your support contact. If you suspect that any of the domains you plan to use for Cloud Identity could have been used by employees to register consumer accounts, consider migrating these user accounts first. For more details, see Assessing existing user accounts. Note: This document refers to the Google Cloud/G Suite Connector by Microsoft gallery app from the Microsoft Azure marketplace. This app is a Microsoft product and is not maintained or supported by Google. Preparing your Cloud Identity or Google Workspace account Create a user for Azure AD To let Azure AD access your Cloud Identity or Google Workspace account, you must create a user for Azure AD in your Cloud Identity or Google Workspace account.</p> <p>The Azure AD user is only intended for automated provisioning. Therefore, it's best to keep it separate from other user accounts by placing it in a separate organizational unit (OU). Using a separate OU also ensures that you can later disable single sign-on for the Azure AD user.</p> <p>To create a new OU, do the following:</p> <p>Open the Admin Console and log in using the super-admin user created when you signed up for Cloud Identity or Google Workspace. In the menu, go to Directory &gt; Organizational units. Click Create organizational unit and provide an name and description for the OU: Name: Automation Description: Automation users Click Create. Create a user account for Azure AD and place it in the Automation OU:</p> <p>In the menu, go to Directory &gt; Users and click Add new user to create a user. Provide an appropriate name and email address such as the following:</p> <p>First Name: Azure AD Last Name: Provisioning Primary email: azuread-provisioning</p> <p>Keep the primary domain for the email address.</p> <p>Click Manage user's password, organizational unit, and profile photo and configure the following settings:</p> <p>Organizational unit: Select the Automation OU that you created previously. Password: Select Create password and enter a password. Ask for a password change at the next sign-in: Disabled. Click Add new user.</p> <p>Click Done.</p> <p>Assign privileges to Azure AD To let Azure AD create, list, and suspend users and groups in your Cloud Identity or Google Workspace account, you must grant the azuread-provisioning user additional privileges as follows:</p> <p>To allow Azure AD to manage all users, including delegated administrators and super-admin users, you must make the azuread-provisioning user a super-admin.</p> <p>To allow Azure AD to manage non-admin users only, it's sufficient to make the azuread-provisioning user a delegated administrator. As a delegated administrator, Azure AD can't manage other delegated administrators or super-admin users.</p> <p>Super-admin Delegated administrator Note: The super-admin role grants the user full access to Cloud Identity, Google Workspace, and Google Cloud resources. To make the azuread-provisioning user a super-admin, do the following:</p> <p>Locate the newly created user in the list and click the user's name to open their account page. Under Admin roles and privileges, click Assign roles. Enable the super-admin role. Click Save. Warning: To protect the user against credential theft and malicious use, we recommend that you enable 2-step verification for the user. For more details on how to protect super-admin users, see Security best practices for administrator accounts. Register domains In Cloud Identity and Google Workspace, users and groups are identified by email address. The domains used by these email addresses must be registered and verified first.</p> <p>Prepare a list of DNS domains that you need to register:</p> <p>If you plan to map users by UPN, include all domains used by UPNs. If in doubt, include all custom domains of your Azure AD tenant. If you plan to map users by email address, include all domains used in email addresses. The list of domains might be different from the list of custom domains of your Azure AD tenant. If you plan to provision groups, amend the list of DNS domains:</p> <p>If you plan to map groups by email address, include all domains used in group email addresses. If in doubt, include all custom domains of your Azure AD tenant. If you plan to map groups by name, include a dedicated subdomain like groups.PRIMARY_DOMAIN, where PRIMARY_DOMAIN is the primary domain name of your Cloud Identity or Google Workspace account. Now that you've identified the list of DNS domains, you can register any missing domains. For each domain on the list not yet registered, perform the following steps:</p> <p>In the Admin Console, go to Account &gt; Domains &gt; Manage domains. Click Add/remove domains. Click Add a domain. Enter the domain name and select Secondary domain. Click Add domain and start verification and follow the instructions to verify ownership of the domain. Configuring Azure AD provisioning Create an enterprise application You are now ready to connect Azure AD to your Cloud Identity or Google Workspace account by setting up the Google Cloud/G Suite Connector by Microsoft gallery app from the Microsoft Azure marketplace.</p> <p>Note: This app is a Microsoft product and is not maintained or supported by Google. The gallery app can be configured to handle both user provisioning and single sign-on. In this document, you use two instances of the gallery app\u2014one for user provisioning and one for single sign-on.</p> <p>First, create an instance of the gallery app to handle user provisioning:</p> <p>Open the Azure portal and sign in as a user with global administrator privileges. Select Azure Active Directory &gt; Enterprise applications. Click New application. Search for Google Cloud, and then click the Google Cloud/G Suite Connector by Microsoft item in the result list. Set the name of the application to Google Cloud (Provisioning). Click Create. Adding the application may take a few seconds, you should then be redirected to a page titled Google Cloud (Provisioning) - Overview. In the menu on the left, click Manage &gt; Properties: Set Enabled for users to sign-in to No. Set User assignment required to No. Set Visible to users to No. Click Save. In the menu on the left, click Manage &gt; Provisioning: Click Get started. Change Provisioning Mode to Automatic. Click Admin Credentials &gt; Authorize. Sign in using the azuread-provisioning@DOMAIN user you created earlier, where DOMAIN is the primary domain of your Cloud Identity or Google Workspace account. Because this is the first time you've signed on using this user, you are asked to accept the Google Terms of Service and privacy policy. If you agree to the terms, click Accept. Confirm access to the Cloud Identity API by clicking Allow. Click Test Connection to verify that Azure AD can successfully authenticate with Cloud Identity or Google Workspace. Click Save. Configure user provisioning The right way to configure user provisioning depends on whether you intend to map users by email address or by UPN.</p> <p>UPN UPN: domain substitution Email address Under Mappings, click Provision Azure Active Directory Users. Under Attribute Mapping, select the row userPrincipalName and set Source Attribute to mail. Select the row surname and set Default value if null to . Select the row givenName and set Default value if null to . Click OK. Click Save. Confirm that saving changes will result in users and groups being resynchronized by clicking Yes. Click X to close the Attribute Mapping dialog. You must configure mappings for primaryEmail, name.familyName, name.givenName, and suspended. All other attribute mappings are optional.</p> <p>When you configure additional attribute mappings, note the following:</p> <p>The Google Cloud/G Suite Connector by Microsoft gallery currently doesn't let you assign email aliases. The Google Cloud/G Suite Connector by Microsoft gallery currently doesn't let you assign licenses to users. As a workaround, consider setting up automatic licensing for organizational units. To assign a user to an organization unit, add a mapping for OrgUnitPath. The path must begin with a / character and must refer to an organizational unit that already exists, for example /employees/engineering. Configure group provisioning The right way to configure group provisioning depends on whether your groups are mail-enabled. If groups aren't mail-enabled, or if groups use an email address ending with \"onmicrosoft.com\", you can derive an email address from the group's name.</p> <p>No group mapping Name Email address If you map groups by email address, keep the default settings. Configure user assignment If you know that only a certain subset of users need access to Google Cloud, you can optionally restrict the set of users to be provisioned by assigning the enterprise app to specific users or groups of users.</p> <p>If you want all users to be provisioned, you can skip the following steps.</p> <p>In the menu on the left, click Manage &gt; Users and groups. Click Add user. Select Users. Select the users or groups you want to provision. If you select a group, all members of this group are automatically provisioned. Click Select. Click Assign. Enable automatic provisioning The next step is to configure Azure AD to automatically provision users to Cloud Identity or Google Workspace:</p> <p>In the menu on the left, click Manage &gt; Provisioning. Select Edit provisioning. Set Provisioning Status to On. Under Settings, set Scope to one of the following:</p> <p>Sync only assigned users and groups if you have configured user assignment. Sync all users and groups otherwise. If this box to set the scope isn't displayed, click Save and refresh the page.</p> <p>Click Save.</p> <p>Azure AD starts an initial synchronization. Depending on the number of users and groups in the directory, this process can take several minutes or hours. You can refresh the browser page to see the status of the synchronization at the bottom of the page or select Audit Logs in the menu to see more details.</p> <p>After the initial synchronization has completed, Azure AD will periodically propagate updates from Azure AD to your Cloud Identity or Google Workspace account. For further details on how Azure AD handles user and group modifications, see Mapping the user lifecycle and Mapping the group lifecycle.</p> <p>Troubleshooting If the synchronization doesn't start within five minutes, you can force it to start by doing the following:</p> <p>Set Provisioning Status to Off. Click Save. Set Provisioning Status to On. Click Save. Check Restart provisioning. Click Save. Confirm restarting the synchronization by clicking Yes. If synchronization still doesn't start, click Test Connection to verify that your credentials have been saved successfully.</p> <p>Configuring Azure AD for single sign-on Although all relevant Azure AD users are now automatically being provisioned to Cloud Identity or Google Workspace, you cannot use these users to sign in yet. To allow users to sign in, you still need to configure single sign-on.</p> <p>Create an enterprise application Create a second enterprise application to handle single sign-on:</p> <p>In the Azure portal, go to Azure Active Directory &gt; Enterprise applications. Click New application. Search for Google Cloud, and then click Google Cloud/G Suite Connector by Microsoft in the result list. Set the name of the application to Google Cloud. Click Add.</p> <p>Adding the application may take a few seconds. You are then redirected to a page titled Google Cloud - Overview.</p> <p>In the menu on the left, click Manage &gt; Properties.</p> <p>Set Enabled for users to sign-in to Yes.</p> <p>Set User assignment required to Yes unless you want to allow all users to use single sign-on.</p> <p>Click Save.</p> <p>Configure user assignment If you already know that only a certain subset of users need access to Google Cloud, you can optionally restrict the set of users to be allowed to sign in by assigning the enterprise app to specific users or groups of users.</p> <p>If you set User assignment required to No before, then you can skip the following steps.</p> <p>In the menu on the left, click Manage &gt; Users and groups. Click Add user. Select Users and groups/None Selected. Select the users or groups you want to allow single sign-on for. Click Select. Click Assign. Configure SAML settings To enable Cloud Identity to use Azure AD for authentication, you must adjust some settings:</p> <p>In the menu on the left, click Manage &gt; Single sign-on. On the ballot screen, click the SAML card. On the Basic SAML Configuration card, click edit Edit. In the Basic SAML Configuration dialog, enter the following settings: Identifier (Entity ID): google.com Reply URL: https://www.google.com/ Sign on URL: https://www.google.com/a/PRIMARY_DOMAIN/ServiceLogin?continue=https://console.cloud.google.com/, replacing PRIMARY_DOMAIN with the primary domain name used by your Cloud Identity or Google Workspace account. Click Save, and then dismiss the dialog by clicking X. On the SAML Signing Certificate card, find the entry labeled Certificate (Base 64) and click Download to download the certificate to your local computer. On the Set up Google Cloud card, look for Login URL. You need this URL shortly. The remaining steps differ depending on whether you map users by email address or by UPN.</p> <p>UPN UPN: domain substitution Email address On the User Attributes &amp; Claims card, click edit Edit. Select the row labeled Unique User Identifier (Name ID). Change Source attribute to user.mail. Click Save. Delete all claims listed under Additional claims. To delete all records, click more_horiz, and then click Delete.</p> <p>User Attributes &amp; Claims dialog.</p> <p>Dismiss the dialog by clicking close.</p> <p>Configuring Cloud Identity or Google Workspace for single sign-on Now that you've prepared Azure AD for single sign-on, you can enable single sign-on in your Cloud Identity or Google Workspace account:</p> <p>Open the Admin Console and log in using a super-admin user. In the menu, click Show more and go to Security &gt; Authentication &gt; SSO with third-party IdP. Click Add SSO profile.</p> <p>Note: Don't use the Add SAML profile button. Set Setup SSO with third party identity provider to enabled.</p> <p>Enter the following settings:</p> <p>Sign-in page URL: Enter the Azure AD Login URL. The Login URL is on the Set up Google Cloud card in the Azure Portal under Configuration URLs &gt; Login URL. Sign-out page URL: https://login.microsoftonline.com/common/wsfederation?wa=wsignout1.0 Change password URL: https://account.activedirectory.windowsazure.com/changepassword.aspx Under Verification certificate, click Upload certificate, and then pick the token signing certificate that you downloaded previously.</p> <p>Click Save.</p> <p>Update the SSO settings for the Automation OU to disable single sign-on:</p> <p>Under Manage SSO profile assignments, click Manage. Expand Organizational units and select the Automation OU. Change the SSO profile assignment from Organization's third-party SSO profile to None. Click Override. The Azure AD token signing certification is valid only for several months. You must rotate the certificate before it expires. For more information, see Rotate a single sign-on certificate later in this document.</p> <p>Consider configuring Azure AD to send you notification emails ahead of certificate expiration to avoid certificate expiration from impacting users.</p> <p>Test single sign-on Now that you've completed the single sign-on configuration in both Azure AD and Cloud Identity or Google Workspace, you can access Google Cloud in two ways:</p> <p>Through the list of apps in your Microsoft Office portal. Directly by opening https://console.cloud.google.com/. To check that the second option works as intended, run the following test:</p> <p>Pick an Azure AD user that has been provisioned to Cloud Identity or Google Workspace and that doesn't have super-admin privileges assigned. Users with super-admin privileges always have to sign in using Google credentials and are therefore not suitable for testing single sign-on. Open a new browser window and go to https://console.cloud.google.com/. In the Google Sign-In page that appears, enter the email address of the user and click Next. If you use domain substitution, this address must be the email address with the substitution applied.</p> <p>Google Sign-In dialog.</p> <p>You are redirected to Azure AD and will see another sign-in prompt. Enter the email address of the user (without domain substitution) and click Next.</p> <p>Azure AD sign-in dialog.</p> <p>After entering your password, you are prompted whether to stay signed in or not. For now, choose No.</p> <p>After successful authentication, Azure AD should redirect you back to Google Sign-In. Because this is the first time you've signed in using this user, you are asked to accept the Google Terms of Service and privacy policy.</p> <p>If you agree to the terms, click Accept.</p> <p>You are redirected to the Google Cloud console, which asks you to confirm preferences and accept the Google Cloud Terms of Service.</p> <p>If you agree to the terms, choose Yes and click Agree and continue.</p> <p>Click the avatar icon on the top left of the page, and then click Sign out.</p> <p>You are redirected to an Azure AD page confirming that you have been successfully signed out.</p> <p>Keep in mind that users with super-admin privileges are exempted from single sign-on, so you can still use the Admin Console to verify or change settings.</p> <p>Rotate a single sign-on certificate The Azure AD token signing certificate is valid for only several months, and you must replace the certificate before it expires.</p> <p>To rotate a signing certificate, add an additional certificate to the Azure AD application:</p> <p>In the Azure portal, go to Azure Active Directory &gt; Enterprise applications and open the application that you created for single sign-on. In the menu on the left, click Manage &gt; Single sign-on. On the SAML Signing Certificate card, click edit Edit.</p> <p>You see a list of one or more certificates. One certificate is marked as Active.</p> <p>Click New certificate.</p> <p>Keep the default signing settings and click Save.</p> <p>The certificate is added to the list of certificates and is marked as Inactive.</p> <p>Select the new certificate and click more_horiz &gt; Base64 certificate download.</p> <p>Keep the browser window open and don't close the dialog.</p> <p>To use the new certificate, do the following:</p> <p>Open a new browser tab or window. Open the Admin Console and log in using a super-admin user. In the menu, click Show more and go to Security &gt; Authentication &gt; SSO with third-party IdP. Click SSO profile for your organization. Click Replace certificate and select the new certificate that you downloaded previously.</p> <p>Caution: After you save changes, your Cloud Identity or Google Workspace account no longer accepts the old Azure AD signing certificate. Click Save.</p> <p>Return to the Azure AD portal and the SAML Signing Certificate dialog.</p> <p>Select the new certificate and click more_horiz &gt; Make certificate active.</p> <p>Click Yes to activate the certificate.</p> <p>Azure AD now uses the new signing certificate.</p> <p>Test that SSO still works as expected. For more information, see Test single sign-on.</p> <p>Clean up To avoid incurring charges to your Google Cloud account for the resources used in this tutorial, either delete the project that contains the resources, or keep the project and delete the individual resources.</p> <p>To disable single sign-on in your Cloud Identity or Google Workspace account, follow these steps:</p> <p>Open the Admin Console and log in using the super-admin user created when signing up for Cloud Identity or Google Workspace. In the menu, go to Security &gt; Settings. Click Set up single sign-on (SSO) with a third party IdP. Ensure that Set up SSO with third party identity provider is disabled. You can remove single sign-on and provisioning settings in Azure AD as follows:</p> <p>In the Azure portal, go to Azure AD &gt; Enterprise applications. From the list of applications, choose Google Cloud. In the menu on the left, click Manage &gt; Single sign-on. Click Delete. Confirm the deletion by clicking Yes.</p>"},{"location":"AMRT/Services/suuf/","title":"Suuf","text":"<p>fsdfsdf</p>"},{"location":"Help/code/","title":"Code","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"Help/code/#code-annotation-examples","title":"Code Annotation Examples","text":""},{"location":"Help/code/#codeblocks","title":"Codeblocks","text":"<p>Install Python <code>sudo apt install python3</code>.</p>"},{"location":"Help/code/#code-for-a-specific-language","title":"Code for a specific language","text":"<p>Some more code with the <code>py</code> at the start:</p> <pre><code>import tensorflow as tf\ndef whatever()\n</code></pre>"},{"location":"Help/code/#with-a-title","title":"With a title","text":"bubble_sort.py<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"Help/code/#highlighting-lines","title":"Highlighting lines","text":"<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"Help/code/#icons-and-emojs","title":"Icons and Emojs","text":""},{"location":"Help/guidesandinformation/","title":"Features","text":""},{"location":"Help/guidesandinformation/#examples-of-admonitions","title":"Examples of Admonitions","text":"<p>Warning</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Abstract</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Info</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Tip</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Success</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Question</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Warning2</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Failure</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Danger</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Bug</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Example</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Quote</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"Help/guidesandinformation/#changing-titles-of-the-admonitions","title":"Changing Titles of the Admonitions","text":"<p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Phasellus posuere in sem ut cursus</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"Help/guidesandinformation/#no-title-admonitions","title":"No Title Admonitions","text":"<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"Help/guidesandinformation/#buttons","title":"Buttons","text":"<p>Subscribe to our newsletter</p>"},{"location":"Help/guidesandinformation/#primary-buttons","title":"Primary Buttons","text":"<p>Subscribe to our newsletter</p>"},{"location":"Help/guidesandinformation/#icon-buttons","title":"Icon Buttons","text":"<p>Send </p>"},{"location":"Help/guidesandinformation/#code-block","title":"Code Block","text":"<pre><code>import tensorflow as tf\n</code></pre>"},{"location":"Help/guidesandinformation/#code-block-with-title","title":"Code Block with Title","text":"bubble_sort.py<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"Help/guidesandinformation/#code-block-with-line-numbers","title":"Code Block with Line Numbers","text":"<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"Help/guidesandinformation/#code-block-with-highlighted-lines","title":"Code Block with Highlighted Lines","text":"<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"Help/guidesandinformation/#using-flowcahrts","title":"Using Flowcahrts","text":"<pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre>"},{"location":"Help/guidesandinformation/#using-sequence-diagrams","title":"Using Sequence Diagrams","text":"<pre><code>sequenceDiagram\n  autonumber\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!</code></pre>"},{"location":"Help/guidesandinformation/#using-sate-diagrams","title":"Using Sate Diagrams","text":"<pre><code>stateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]</code></pre>"},{"location":"Help/guidesandinformation/#using-class-diagrams","title":"Using Class Diagrams","text":"<pre><code>classDiagram\n  Person &lt;|-- Student\n  Person &lt;|-- Professor\n  Person : +String name\n  Person : +String phoneNumber\n  Person : +String emailAddress\n  Person: +purchaseParkingPass()\n  Address \"1\" &lt;-- \"0..1\" Person:lives at\n  class Student{\n    +int studentNumber\n    +int averageMark\n    +isEligibleToEnrol()\n    +getSeminarsTaken()\n  }\n  class Professor{\n    +int salary\n  }\n  class Address{\n    +String street\n    +String city\n    +String state\n    +int postalCode\n    +String country\n    -validate()\n    +outputAsLabel()  \n  }</code></pre>"},{"location":"Help/guidesandinformation/#unity-diagrams","title":"Unity Diagrams","text":"<pre><code>erDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  LINE-ITEM {\n    string name\n    int pricePerUnit\n  }\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses</code></pre>"},{"location":"Help/guidesandinformation/#h","title":"h","text":""},{"location":"Knowledge/Apps/CertManager/","title":"Cert-Manager","text":"<p>Cert-manager adds certificates and certificate issuers as resource types in Kubernetes Clusters, and simplifies the process of obtaining, renewing and using those certificates.</p> <p>Documentation &amp; Project Homepage: Cert-Manager Docs</p>"},{"location":"Knowledge/Apps/CertManager/#self-signed-certificates","title":"Self-Signed Certificates","text":""},{"location":"Knowledge/Apps/CertManager/#upload-existing-cakey-and-cacrt-files-option-1","title":"Upload existing CA.key and CA.crt files (Option 1)","text":"<ol> <li>Create a self-signed CA creating a ca.key (private-key) and ca.crt (certificate)</li> </ol> <p>(ca.key) <pre><code>openssl genrsa -out ca.key 4096\n</code></pre></p> <p>(ca.crt) <pre><code>openssl req -new -x509 -sha256 -days 365 -key ca.key -out ca.crt\n</code></pre></p> <ol> <li>Convert the files to a one line base64 decoded string (only works on Linux base64 tool)</li> </ol> <pre><code>cat ca.key | base64 -w 0\n</code></pre> <ol> <li>Create a new ssl secret object using the strings</li> </ol> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: ssl-issuer-secret\n  # (Optional) Metadata\n  # ---\n  # namespace: your-namespace\ntype: Opaque\ndata:\n  tls.crt: &lt;base64-decoded-string&gt;\n  tls.key: &lt;base64-decoded-string&gt;\n</code></pre> <ol> <li>Create a new ClusterIssuer or Issuer object by using the ssl secret</li> </ol> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: selfsigned-issuer\n  # (Optional) Metadata\n  # ---\n  # namespace: your-namespace\nspec:\n  ca:\n    secretName: ssl-issuer-secret\n</code></pre>"},{"location":"Knowledge/Apps/CertManager/#create-ca-through-cert-manager-option-2","title":"Create CA through Cert-manager (Option 2)","text":"<p>Create a new ClusterIssuer or Issuer object by using the selfSigned Attribute.</p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: root-issuer\nspec:\n  selfSigned: {}\n</code></pre>"},{"location":"Knowledge/Apps/CertManager/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Knowledge/Apps/CertManager/#common-errors","title":"Common Errors","text":"<p>DNS Record not yet propagated</p> <p>The error, <code>Waiting for DNS-01 challenge propagation: DNS record for \"your-dns-record\" not yet propagated.</code>, might occur in the <code>challenge</code> object. Cert-Manager creates a TXT Record on the DNS provider and checks, whether the record is existing, before issuing the certificate. In a split-dns environment, this could be a problem when internal DNS Servers can't resolve the TXT Record on the Cloud DNS. You can use the <code>extraArgs</code> <code>--dns01-recursive-nameservers-only</code>, and <code>--dns01-recursive-nameservers=8.8.8.8:53,1.1.1.1:53</code>, to specific the DNS Resolvers used for the challenge.</p> <p>No solver found</p> <p>The error, <code>Failed to determine a valid solver configuration for the set of domains on the Order: no configured challenge solvers can be used for this challenge</code> might occur in the <code>order</code> object, when no solver can't be found for the DNS Hostname. Make sure your solvers have a corrent <code>dnsZones</code> configured that matches the DNS Hostnames Zone.</p>"},{"location":"Knowledge/Apps/argocd/","title":"Argo CD","text":"<p>Argo CD is a declarative, GitOps continuous delivery tool for **Kubernetes. It allows application definitions, configurations, and environments should be declarative and version controlled. Application deployment and lifecycle management should be automated, auditable, and easy to understand.</p> <p>Documentation &amp; Project Homepage: Argo CD Docs</p>"},{"location":"Knowledge/Apps/argocd/#installation","title":"Installation","text":"<ol> <li>Install Argo CD on a Kubernetes Cluster, using kubectl.</li> </ol> <pre><code>kubectl create namespace argocd\n\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n</code></pre> <ol> <li>Add **Traefik IngressRoute. </li> </ol> <pre><code>apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: argocd-server\n  namespace: argocd\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - kind: Rule\n      match: Host(`argocd.example.com`)\n      priority: 10\n      services:\n        - name: argocd-server\n          port: 80\n    - kind: Rule\n      match: Host(`argocd.example.com`) &amp;&amp; Headers(`Content-Type`, `application/grpc`)\n      priority: 11\n      services:\n        - name: argocd-server\n          port: 80\n          scheme: h2c\n  tls:\n    certResolver: default\n</code></pre> <ol> <li>Disable internal TLS</li> </ol> <p>Edit the <code>--insecure</code> flag in the <code>argocd-server</code> command of the argocd-server deployment, or simply set <code>server.insecure: \"true\"</code> in the <code>argocd-cmd-params-cm</code> ConfigMap.</p>"},{"location":"Knowledge/Apps/argocd/#get-the-admin-password","title":"Get the admin password","text":"<p>For Argo CD v1.8 and earlier, the initial password is set to the name of the server pod, for Argo CD v1.9 and later, the initial password is available from a secret named <code>argocd-initial-admin-secret</code>.</p> <pre><code>kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\n</code></pre>"},{"location":"Knowledge/Apps/argocd/#configuration","title":"Configuration","text":""},{"location":"Knowledge/Apps/argocd/#add-private-github-repositories","title":"Add private GitHub Repositories","text":"<ol> <li> <p>Create a github token: https://github.com/settings/tokens</p> </li> <li> <p>Add new repository in ArgoCD via **kubectl or the GUI</p> </li> </ol> <pre><code>apiVersion: v1  \nkind: Secret  \nmetadata:  \n  name: repo-private-1\n  labels:  \n    argocd.argoproj.io/secret-type: repository  \nstringData:  \n  url: https://github.com/xcad2k/private-repo \n  password: &lt;github-token&gt; \n  username: not-used\n</code></pre> <ol> <li>Verify new repository is connected</li> </ol>"},{"location":"Knowledge/Apps/argocd/#declarative-application-and-applicationset","title":"Declarative Application and ApplicationSet","text":"<p>Apart from using the WebUI to add managed apps to ArgoCD, you can configure <code>Application</code> and <code>ApplicationSet</code> resources. This enables you to define not only ArgoCD and your apps as code, but also the definition which application you want to manage. With apps defined as YAML via an <code>Application</code>, you can e.g. deploy the app within a CI/CD pipeline that deploys your Argo instance.</p> <p>There are two types of resources. <code>Application</code> and <code>ApplicationSet</code>. The main difference is, that you can specify so called inline generators which allow you to template your Application definition. If you manage multiple clusters with ArgoCD and you want to get an <code>Application</code> deployed with cluster specific parameters you want to use an <code>ApplicationSet</code>.</p> <p>Below, you find an example for an <code>Application</code> and an <code>ApplicationSet</code>.</p> <p>Application:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: guestbook\n  namespace: argocd\nspec:\n  destination:\n    namespace: default\n    server: 'https://kubernetes.default.svc'\n  source:\n    path: kustomize-guestbook\n    repoURL: 'https://github.com/argoproj/argocd-example-apps'\n    targetRevision: HEAD\n  project: default\n  syncPolicy:\n    automated:\n      prune: false\n      selfHeal: false\n</code></pre> <p>ApplicationSet:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: guestbook\n  namespace: argocd\nspec:\n  generators:\n  - clusters: {} # This is a generator, specifically, a cluster generator.\n  template: \n    # This is a template Argo CD Application, but with support for parameter substitution.\n    metadata:\n      name: '{{name}}-guestbook'\n    spec:\n      project: \"default\"\n      source:\n        repoURL: https://github.com/argoproj/argocd-example-apps/\n        targetRevision: HEAD\n        path: kustomize-guestbook\n      destination:\n        server: '{{server}}'\n        namespace: default\n</code></pre>"},{"location":"Knowledge/Apps/argocd/#further-information","title":"Further information","text":"<p>More examples and tutorials regarding ArgoCD can be found in the link list below:</p> <ul> <li>Basic tutorial for installation and configuration: Let loose the squid - Deploy ArgoCD the declarative way</li> <li>Writing ArgoCD Plugins: ArgoCD Custom Plugins</li> </ul>"},{"location":"Knowledge/Apps/bind9/","title":"BIND9","text":"<p>BIND9 (Berkeley Internet Name Domain version 9) is an open-source [[DNS]] (Domain Name System) software system. It is the most widely used DNS server software on the Internet and is maintained by the Internet Systems Consortium (ISC). BIND9 provides a robust and scalable platform for resolving domain names into IP addresses and vice versa, as well as supporting advanced DNS features such as [[DNSSEC]] (DNS Security Extensions), dynamic updates, and incremental zone transfers. BIND9 runs on a variety of operating systems, including [[Linux]], [[Unix]], and [[Windows]], and is highly configurable and extensible through the use of plugins and modules.</p> <p>Project Homepage: https://www.isc.org/bind/</p>"},{"location":"Knowledge/Apps/bind9/#installation","title":"Installation","text":"<p>ISC provides executables for Windows and packages for Ubuntu, CentOS, Fedora  and Debian - BIND 9 ESV, Debian - BIND 9 Stable, Debian - BIND 9 Development version. Most operating systems also offer BIND 9 packages for their users. These may be built with a different set of defaults than the standard BIND 9 distribution, and some of them add a version number of their own that does not map exactly to the BIND 9 version.</p>"},{"location":"Knowledge/Apps/bind9/#ubuntu-linux","title":"Ubuntu Linux","text":"<p>BIND9 is available in the Main repository. No additional repository needs to be enabled for BIND9.</p> <pre><code>sudo apt install bind9\n</code></pre>"},{"location":"Knowledge/Apps/bind9/#ubuntu-docker","title":"Ubuntu Docker","text":"<p>As part of the Long Term Supported OCI Images, Canonical offers Bind9 as a hardened and maintained Docker.</p> <pre><code>docker run -d --name bind9-container -e TZ=UTC -p 30053:53 ubuntu/bind9:9.18-22.04_beta\n</code></pre>"},{"location":"Knowledge/Apps/bind9/#configuration","title":"Configuration","text":"<p>BIND 9 uses a single configuration file called <code>named.conf</code>, which is typically located in either <code>/etc/bind</code>, <code>/etc/namedb</code> or <code>/usr/local/etc/namedb</code>.</p> <p>The <code>named.conf</code> consists of <code>logging</code>, and <code>options</code> blocks, and <code>category</code>, <code>channel</code>, <code>directory</code>, <code>file</code> and <code>severity</code> statements.</p>"},{"location":"Knowledge/Apps/bind9/#named-config","title":"Named Config","text":"<pre><code>options {\n    ...\n};\n\nzone \"domain.tld\" {\n    type primary;\n    file \"domain.tld\";\n};\n</code></pre>"},{"location":"Knowledge/Apps/bind9/#zone-file","title":"Zone File","text":"<p>Depending on the functionality of the system, one or more <code>zone</code> files is required.</p> <pre><code>; base zone file for domain.tld\n$TTL 2d    ; default TTL for zone\n\n$ORIGIN domain.tld. ; base domain-name\n\n; Start of Authority RR defining the key characteristics of the zone (domain)\n@         IN      SOA   ns1.domain.tld. hostmaster.domain.tld. (\n                                2022121200 ; serial number\n                                12h        ; refresh\n                                15m        ; update retry\n                                3w         ; expiry\n                                2h         ; minimum\n                                )\n\n; name server RR for the domain\n           IN      NS      ns1.domain.tld.\n\n; mail server RRs for the zone (domain)\n        3w IN      MX  10  mail.domain.tld.\n\n; domain hosts includes NS and MX records defined above\n; plus any others required\n; for instance a user query for the A RR of joe.domain.tld will\n; return the IPv4 address 192.168.254.6 from this zone file\nns1        IN      A       192.168.254.2\nmail       IN      A       192.168.254.4\njoe        IN      A       192.168.254.6\nwww        IN      A       192.168.254.7\n</code></pre>"},{"location":"Knowledge/Apps/bind9/#soa-start-of-authority","title":"SOA (Start of Authority)","text":"<p>A start of authority record is a type of resource record in the Domain Name System (DNS) containing administrative information about the zone, especially regarding zone transfers. The SOA record format is specified in RFC 1035.</p> <pre><code>@         IN      SOA   ns1.domain.tld. hostmaster.domain.tld. (\n                                2022121200 ; serial number\n                                12h        ; refresh\n                                15m        ; update retry\n                                3w         ; expiry\n                                2h         ; minimum\n                                )\n</code></pre>"},{"location":"Knowledge/Apps/bind9/#forwarders","title":"Forwarders","text":"<p>DNS forwarders are servers that resolve DNS queries on behalf of another DNS server.</p> <p>To configure bind9 as a forwarding DNS server, you need to add a <code>forwarders</code> clause inside the <code>options</code> block. The <code>forwarders</code> clause specifies a list of IP addresses of other DNS servers that bind9 will forward queries to.</p> <pre><code>options {\n    // ... other options ...\n    forwarders {\n        8.8.8.8; // Google Public DNS\n        1.1.1.1; // Cloudflare DNS\n    };\n};\n</code></pre>"},{"location":"Knowledge/Apps/bind9/#access-control","title":"Access Control","text":"<p>To configure permissions in BIND9, you can use the \u201cacl\u201d statement to define access control lists, and then use the \u201callow-query\u201d and \u201callow-transfer\u201d statements to specify which hosts or networks are allowed to query or transfer zones.</p> <pre><code>acl \"trusted\" {\n    192.168.1.0/24;\n    localhost;\n};\n\noptions {\n    // ...\n    allow-query { any; };\n    allow-transfer { \"trusted\"; };\n    // ...\n};\n\nzone \"example.com\" {\n    // ...\n    allow-query { \"trusted\"; };\n    // ...\n};\n</code></pre> <p>In this example, we define an ACL called \u201ctrusted\u201d that includes the 192.168.1.0/24 network and the local host. We then specify that hosts in this ACL are allowed to transfer zones, and that any host is allowed to query.</p> <p>For the \u201cexample.com\u201d zone, we specify that only hosts in the \u201ctrusted\u201d ACL are allowed to query.</p> <p>You can also use other ACL features, such as \u201callow-recursion\u201d and \u201callow-update\u201d, to further control access to your DNS server.</p>"},{"location":"Knowledge/Apps/bind9/#dynamic-updates","title":"Dynamic Updates","text":"<p>Dynamic updates in BIND allow for the modification of DNS records in real-time without having to manually edit zone files. </p>"},{"location":"Knowledge/Apps/bind9/#secure-dns-updates-with-tsig-key","title":"Secure DNS updates with TSIG Key","text":"<p>A TSIG (Transaction SIGnature) key is a shared secret key used to authenticate dynamic DNS updates between a DNS client and server. It provides a way to securely sign and verify DNS messages exchanged during dynamic updates.</p> <p>To create a TSIG key for use with dynamic updates, the <code>tsig-keygen</code> command can be used.</p> <pre><code>tsig-keygen -a hmac-sha256\n</code></pre> <p>To add the TSIG key to the zone configuration, the \"key\" statement must be added to the \"allow-update\" statement in the named.conf file. For example:</p> <pre><code>zone \"example.com\" {\n    type master;\n    file \"example.com.zone\";\n    allow-update { key \"tsig-key\"; };\n};\n</code></pre> <p>In this example, the \"allow-update\" statement now uses the TSIG key, to allow updates to the \"example.com\" zone.</p>"},{"location":"Knowledge/Apps/bitwarden/","title":"Bitwarden(Self-Hosted)","text":""},{"location":"Knowledge/Apps/bitwarden/#linux","title":"Linux","text":""},{"location":"Knowledge/Apps/cloudflaretunnels/","title":"Cloudflare Tunnels","text":""},{"location":"Knowledge/Apps/cloudflaretunnels/#cloudflare-tunnels_1","title":"Cloudflare Tunnels","text":""},{"location":"Knowledge/Apps/cloudflaretunnels/#protect-your-web-servers-from-direct-attack","title":"Protect your web servers from direct attack","text":"<p>From the moment an application is deployed, developers and IT spend time locking it down \u2014 configuring ACLs, rotating IP addresses, and using clunky solutions like GRE tunnels.</p> <p>There\u2019s a simpler and more secure way to protect your applications and web servers from direct attacks: Cloudflare Tunnel.</p> <p>Ensure your server is safe, no matter where it\u2019s running: public cloud, private cloud, Kubernetes cluster, or even a Mac mini under your TV.</p>"},{"location":"Knowledge/Apps/cloudflaretunnels/#i-do-everthing-in-the-cli","title":"I do everthing in the cli","text":"<p>install the cloudflare tunnel service. in my case i will do the install on een ubuntu machine.</p> <pre><code>wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb &amp;&amp; sudo dpkg -i cloudflared-linux-amd64.deb\n</code></pre> <p>When you run the flowing command you get a url. login to cloudflare <pre><code>cloudflared tunnel login\n</code></pre></p> <p>when cloudflare is connected you get a cert.pem. make a note of the location.</p> <p>create the tunnel by name fill the name that you want for the tunnel.</p> <pre><code>cloudflared tunnel create &lt;NAME&gt;\n\n# Take a note where your tunnel credentials are saved.\n</code></pre> <p>create a configuration file in the <code>.cloudflared</code> directory <pre><code>nano /home/$USER/.cloudflared/config.yaml\n</code></pre></p> <p>set the following lines. <pre><code>tunnel: Your-Tunnel-Id\ncredentials-file: /home/$USER/.cloudflared/1d4537b6-67b9-4c75-a022-ce805acd5c0a.json  \n\n1d4537b6-67b9-4c75-a022-ce805acd5c0a.json # Get the json file from previous step.\n</code></pre></p> <p>add your first site example.com</p> <pre><code>cloudflared tunnel route dns &lt;name of the tunnel&gt; &lt;example.com&gt;\n</code></pre> <p>create the ingress. create config.yml file in you .cloudflared directory</p> <pre><code>ingress:\n  - hostname: example.com \n    service: http://internalip:80\n  - hostname: sub.example.com\n    service: http://internalip:88\n  - service: http_status:404 # this is required as a 'catch-all'\n</code></pre> <p>start the tunnel</p> <pre><code>cloudflared tunnel run &lt;name of your tunnel&gt;\n</code></pre> <p>Make a service to run automatic</p> <pre><code>cloudflared service install\n</code></pre> <p>start en enable the service</p> <pre><code>systemctl enable --now cloudflared\n</code></pre>"},{"location":"Knowledge/Apps/grafana/","title":"Grafana","text":"<p>Operational dashboards for your data here, there, or anywhere</p> <p>Project Homepage: Grafana Homepage Documentation: Grafana Docs</p>"},{"location":"Knowledge/Apps/kasm/","title":"KASM Workspaces","text":"<p>Streaming containerized apps and desktops to end-users. The Workspaces platform provides enterprise-class orchestration, data loss prevention, and web streaming technology to enable the delivery of containerized workloads to your browser.</p>"},{"location":"Knowledge/Apps/kasm/#add-self-signed-ssl-certificates","title":"Add self-signed SSL Certificates","text":"<p>...</p> <ol> <li> <p>Stop the kasm services <pre><code>sudo /opt/kasm/bin/stop\n</code></pre></p> </li> <li> <p>Replace <code>kasm_nginx.crt</code> and <code>kasm_nginx.key</code> files <pre><code>sudo cp &lt;your_cert&gt; /opt/kasm/current/certs/kasm_nginx.crt\nsudo cp &lt;your_key&gt; /opt/kasm/current/certs/kasm_nginx.key\n</code></pre></p> </li> <li> <p>Start the Kasm Services <pre><code>sudo /opt/kasm/bin/start\n</code></pre></p> </li> </ol>"},{"location":"Knowledge/Apps/kasm/#custom-images","title":"Custom Images","text":"<p>...</p> <p>Registry <pre><code>https://index.docker.io/v1/\n</code></pre></p> <p>...</p>"},{"location":"Knowledge/Apps/kasm/#add-images-in-kasm","title":"Add Images in KASM","text":"<p>[!attention] You need to pass in a \"tag\" in the Docker Image. Otherwise kasm won't pull and start the image correctly.</p>"},{"location":"Knowledge/Apps/kasm/#docker-run-config","title":"Docker Run Config","text":"<p>Example <pre><code>{\n    \"cap_add\":[\"NET_ADMIN\"],\n    \"devices\":[\"dev/net/tun\",\"/dev/net/tun\"],\n    \"sysctls\":{\"net.ipv6.conf.all.disable_ipv6\":\"0\"}\n}\n</code></pre></p>"},{"location":"Knowledge/Apps/kasm/#troubleshooting","title":"Troubleshooting","text":"<p>...</p>"},{"location":"Knowledge/Apps/kasm/#kasm-agent","title":"KASM Agent","text":"<p>...</p>"},{"location":"Knowledge/Apps/kasm/#database","title":"Database","text":"<p>...</p> <pre><code>sudo docker exec -it kasm_db psql -U kasmapp -d kasm\n</code></pre>"},{"location":"Knowledge/Apps/kasm/#delete-invalid-users-from-user_groups-table","title":"Delete invalid users from user_groups table","text":"<p>...</p> <ol> <li> <p>Check table for invalid entries <pre><code>kasm=# select * from user_groups;\n            user_group_id             |               user_id                |               group_id\n--------------------------------------+--------------------------------------+--------------------------------------\n 07c54672-739f-42d8-befc-bb2ba29fa22d | 71899524-5b31-41ac-a359-1aa8a008b831 | 68d557ac-4cac-42cc-a9f3-1c7c853de0f3\n e291f1f7-86be-490f-9f9b-3a520d4d1dfa | 71899524-5b31-41ac-a359-1aa8a008b831 | b578d8e9-5585-430b-a70b-9935e8acaaa3\n 07b6f450-2bf5-48c0-9c5e-3443ad962fcb |                                      | 68d557ac-4cac-42cc-a9f3-1c7c853de0f3\n 8c4c7242-b2b5-4a7a-89d3-e46d24456e5c |                                      | b578d8e9-5585-430b-a70b-9935e8acaaa3\n</code></pre></p> </li> <li> <p>Delete invalid entries from the table: <pre><code>delete from user_groups where user_id is null;\n</code></pre></p> </li> <li> <p>Verify table <pre><code>kasm=# select * from user_groups;\n            user_group_id             |               user_id                |               group_id\n--------------------------------------+--------------------------------------+--------------------------------------\n 07c54672-739f-42d8-befc-bb2ba29fa22d | 71899524-5b31-41ac-a359-1aa8a008b831 | 68d557ac-4cac-42cc-a9f3-1c7c853de0f3\n e291f1f7-86be-490f-9f9b-3a520d4d1dfa | 71899524-5b31-41ac-a359-1aa8a008b831 | b578d8e9-5585-430b-a70b-9935e8acaaa3\n(2 rows)\n</code></pre></p> </li> </ol>"},{"location":"Knowledge/Apps/longhorn/","title":"Longhorn","text":"<p>Longhorn is a lightweight, reliable and easy-to-use distributed block storage system for Kubernetes.</p> <p>Project Homepage: Longhorn Homepage Documentation: Longhorn Docs</p>"},{"location":"Knowledge/Apps/longhorn/#installation","title":"Installation","text":"<p>You can install Longhorn via Helm. To customize values, follow the Chart Default Values</p> <pre><code>helm repo add longhorn https://charts.longhorn.io\n\nhelm repo update\n\nhelm install longhorn longhorn/longhorn\n</code></pre>"},{"location":"Knowledge/Apps/nginx/","title":"Nginx","text":"<p>Open source web and application server.</p> <p>Project Homepage: Nginx Homepage Documentation: Nginx Unit Docs</p>"},{"location":"Knowledge/Apps/nginx/#basic-configuration-arguments-and-examples","title":"Basic configuration arguments and examples","text":"<p>Logging and debugging:</p> <pre><code>error_log &lt;file&gt; &lt;loglevel&gt;\n    error_log logs/error.log;\n    error_log logs/debug.log debug;\n    error_log logs/error.log notice;\n</code></pre> <p>basic listening ports:</p> <pre><code>listen &lt;port&gt; &lt;options&gt;\n        listen 80;\n        listen 443 ssl http2;\n        listen 443 http3 reuseport; (this is experimental!)\n</code></pre> <p>header modifcations: <pre><code>add_header &lt;header&gt; &lt;values&gt;\n        add_header Alt-svc '$http3=\":&lt;port&gt;\"; ma=&lt;value&gt;'; (this is experimental!)\n\nssl_certificate / ssl_certificate_key\n        ssl_certificate cert.pem;\n        ssl_certificate_key cert.key;\n\nserver_name &lt;domains&gt;\n    server_name domain1.com *.domain1.com\n\nroot &lt;folder&gt;\n    root /var/www/html/domain1;\n\nindex &lt;file&gt;\n    index index.php;\n\nlocation &lt;url&gt; {\n}\n    location / {\n        root index.html;\n        index index.html index.htm;\n    }\n    location / {\n        try_files $uri $uri/ /index.php$is_args$args;\n    }\n    location ~ \\\\.php$ {\n        fastcgi_pass 127.0.0.1:9000;\n        fastcgi_index index.php;\n        fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;\n        include fastcgi_params;\n    }\n    location ~ /\\\\.ht {\n        deny all;\n    }\n    location = /favicon.ico {\n        log_not_found off;\n        access_log off;\n    }\n    location = /robots.txt {\n        log_not_found off;\n        access_log off;\n        allow all;\n    }\n    location ~* .(css|gif|ico|jpeg|jpg|js|png)$ {\n        expires max;\n        log_not_found off;\n}\n</code></pre></p>"},{"location":"Knowledge/Apps/nginx/#reverse-proxy","title":"Reverse Proxy","text":""},{"location":"Knowledge/Apps/nginx/#show-clients-real-ip","title":"Show Client's real IP","text":"<pre><code>server {\n    server_name example.com;\n    location / { \n        proxy_pass http://localhost:4000;\n\n        # Show clients real IP behind a proxy\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n</code></pre>"},{"location":"Knowledge/Apps/passbolt/","title":"Passbolt","text":"<p>Passbolt is a free and open-source password manager built for collaboration. Secure, flexible, and automation ready. Trusted by 10,000 organizations, including Fortune 500 companies, newspapers, governments and defence forces.</p> <p>Project Homepage: https://passbolt.com/</p>"},{"location":"Knowledge/Apps/passbolt/#set-up","title":"Set Up","text":""},{"location":"Knowledge/Apps/passbolt/#create-admin-user","title":"Create admin user","text":"<pre><code>docker-compose exec passbolt su -m -c \"/usr/share/php/passbolt/bin/cake \\\n                                passbolt register_user \\\n                                -u &lt;your_email&gt; \\\n                                -f &lt;first_name&gt; \\\n                                -l &lt;last_name&gt;\\\n                                -r admin\" -s /bin/sh www-data\n</code></pre>"},{"location":"Knowledge/Apps/passbolt/#backup-options","title":"Backup options","text":"<p>Backup database container change database-container to the name of your passbolt database container and change the backup location</p> <p>``` docker exec -i database-container bash -c \\   'mysqldump -u\\({MYSQL_USER} -p\\) ${MYSQL_DATABASE}' \\</p> <p>/path/to/backup.sql <pre><code>### Backup server public and private keys\nchange passbolt-container to the name of your passbolt container\nand change the backup location\n\n   ```\ndocker cp passbolt-container:/etc/passbolt/gpg/serverkey_private.asc \\\n    /path/to/backup/serverkey_private.asc\ndocker cp passbolt-container:/etc/passbolt/gpg/serverkey.asc \\\n    /path/to/backup/serverkey.asc\n</code></pre></p>"},{"location":"Knowledge/Apps/passbolt/#backup-the-avatars","title":"Backup The avatars","text":"<p><code>docker exec -i passbolt-container \\     tar cvfzp - -C /usr/share/php/passbolt/ webroot/img/avatar \\     &gt; passbolt-avatars.tar.gz</code></p>"},{"location":"Knowledge/Apps/portainer/","title":"Portainer","text":"<p>Easily deploy, configure and secure containers in minutes on Docker, Kubernetes, Swarm and Nomad in any cloud, datacenter or device.</p> <p>Project Homepage: Portainer Documentation: Portainer Docs</p>"},{"location":"Knowledge/Cloud/cloudinfo/","title":"What is Cloud-Computing?","text":"<ul> <li>A model that enables businesses to acquire resources for their IT infrastructure needs on demand</li> <li>Cloud resources: Servers, storage, databases, netwroks, software applications, and so on</li> <li>Ensures the instantaneous availability of resources with lower cost and operational overhead</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#benefits","title":"Benefits","text":"<ol> <li>Cost Savings<ul> <li>Helps you reduce capital investment</li> <li>Reduces hardare and software procurement, which further eliminates the need for power and cooling systems</li> <li>Provides cloud services on demand and you are only charged when you use the service</li> </ul> </li> <li>Data Loss Prevention<ul> <li>Cloud computing allows you to store your organizations' valuable data in the cloud rather your own data center storage hardware</li> <li>The cloud provider's data storage solutions typically offer better access, redundancy, and availability than enterprise data centers</li> <li>These solutions help prevent data loss through malfunction, viruses, user errors, or theft</li> </ul> </li> <li>Scalability<ul> <li>Cloud computing enables you to increase or decrease IT infra resources according to your business needs</li> <li>Both manual and automatic scaling options are available with most cloud providers</li> </ul> </li> <li>Flexibility<ul> <li>IT organiztions traditionally focus on various responsibilities, from procuring, hosting, and maintaining IT infra to custumer support and security</li> <li>Because these services are made available as managed services by the cloud provider, organizations can focus on their actual business and not IT management issues </li> </ul> </li> <li>Security<ul> <li>Cloud providers offer data protection services like data encryption and policy-based user management, making cloud security equivalent to conventional systems</li> </ul> </li> <li>Data Analytics<ul> <li>Cloud computing technology generally includes analytics and reporting, which helps track usage</li> <li>This feature allows you to indentify areas of improvement, meet your business goals, and increase organizational efficiency </li> </ul> </li> <li>Collaboration<ul> <li>Cloud computing allows users from different geographic locations to work as a team and collaborate easily and effectively</li> <li>This speeds delivery of applications to market</li> </ul> </li> <li>Data Recovery<ul> <li>Cloud computing provides features and technologies that help companies recover data lost during natural disasters, power outages, and other unforeseen emergencies.</li> </ul> </li> <li>Mobile Access <ul> <li>Cloud applications can provide mobile access to corporate resources</li> <li>This feature is beneficial for employees and customers, allowing them to access a cloud application from anywhere</li> </ul> </li> </ol>"},{"location":"Knowledge/Cloud/cloudinfo/#use-cases","title":"Use Cases","text":"<ul> <li>Faster Testing and Deployment</li> <li>Remote Working</li> <li>Cloud Communication</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#what-is-a-cloud-application","title":"What is a Cloud Application?","text":"<p>A cloud application is a software program that runs in the cloud and is accessed remotely over the network. It has all the functionality of a non cloud based application with the added advantage of being delivered over the network.</p>"},{"location":"Knowledge/Cloud/cloudinfo/#cloud-economics","title":"Cloud Economics","text":"<p>Cloud computing reduces capital expenditures ( CapEx ) by eliminating the need to run and maintain your own infrastructure Your costs shift to operating expenses ( OpEx ), which are generally lower as you only pay for the resources you consume</p>"},{"location":"Knowledge/Cloud/cloudinfo/#operational-efficiencies","title":"Operational Efficiencies","text":"<ul> <li>Reduces Capital Expenses</li> <li>Reduces Staffing Costs</li> <li>Improves Productivity</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#what-is-a-distributed-system","title":"What is a Distributed System?","text":"<p>A distriuted computing system consists of multiple independent software components. These independent software components are located on different systems that communicate in such a way that they appear as a single system to  the end user Note - Cloud computing is based on the  distributed systems model</p>"},{"location":"Knowledge/Cloud/cloudinfo/#types-of-distributed-systems","title":"Types of Distributed Systems","text":"<ol> <li>Peer-to-Peer -&gt; in the peer-to-peer architectural model, responsibilities are uniformly distributed among machines in the system.</li> <li>Client-Server -&gt; In the client-server model, data on the server is accessed by clients.</li> <li>Three-tier -&gt; The three-tier architectural model enables information about the client to be stored in the middle tier.</li> <li>N-tier -&gt; The n-tier architecture allows an application or server to forward requests to additional enterprise services on the network. </li> </ol>"},{"location":"Knowledge/Cloud/cloudinfo/#centralized-vs-distributed-systems","title":"Centralized v/s Distributed Systems","text":""},{"location":"Knowledge/Cloud/cloudinfo/#workloads","title":"Workloads","text":"<ul> <li>The amount of work allocated to a defined computing task at any given time</li> <li>An isolated computing task that is executed indepenedently without any support from external programs or applications </li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#edge-computing","title":"Edge Computing :","text":"<ul> <li>Is a distributed computing model that brings compute and storage workloads closer to the user</li> <li>Decreases latency and saves bandwidth</li> <li>Processes information close to the edge and decentralizes a network</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#workloads-in-distributed-systems","title":"Workloads in distributed systems :","text":"<ul> <li>Are distributed among the available IT resources based on the utilization of each resource</li> <li>Uses an algorithm that consumes runtime logic and distributes the workload among the available IT resouces evenly</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#bare-metal-server","title":"Bare Metal Server","text":"<ul> <li>A physical server assigned to a single tenant </li> <li>Can be modified based on  the  need for performance and security </li> <li>Isolates resources from other tenants and provides security to your business</li> <li>Can be configured for  different cloud  setups</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#cloud-implementations","title":"Cloud Implementations","text":""},{"location":"Knowledge/Cloud/cloudinfo/#types-of-cloud","title":"Types of Cloud","text":""},{"location":"Knowledge/Cloud/cloudinfo/#public-clouds","title":"Public Clouds","text":"<ul> <li>Public Clouds are environments where network infra and resources are made accessible to the public</li> <li>Resources are partitioned and distributed amongst multiple customers or tenants</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#private-clouds","title":"Private Clouds","text":"<ul> <li>Private Clouds environments are privately owned and hosted by an enterprise.</li> <li>Resources are genrally made accessible to a private organization and their customers and partners<ul> <li>Managed private clouds are deployed and fully managed by a third-party, reducing the IT staffing needs for the enterprise</li> <li>Dedicated private clouds are hosted on a public or private cloud to server a particular department within an enterprise </li> </ul> </li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#hybrid-clouds","title":"Hybrid Clouds","text":"<ul> <li>Hybrid Clouds are cloud environments that appear as a single cloud although they are built from multiple clouds ( connected through LANs, WANs, VPNs and/or APIs )</li> <li>Offer flexibilty in deployment options by enabling workloads to move between private and public clouds based on computing needs</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#multi-clouds","title":"Multi Clouds","text":"<ul> <li>Multiclouds are cloud envirenments that offer more than one cloud service from more than one public cloud service provider</li> <li>Resources are deployed accross different cloud availabilty zones and regions</li> <li>All Hybrid Clouds are Multi Clouds</li> </ul>"},{"location":"Knowledge/Cloud/cloudinfo/#top-public-cloud-providers","title":"Top Public Cloud Providers","text":""},{"location":"Knowledge/Cloud/cloudinfo/#microsoft-azure","title":"Microsoft Azure","text":""},{"location":"Knowledge/Cloud/cloudinfo/#amazon-web-services","title":"Amazon Web Services","text":""},{"location":"Knowledge/Cloud/cloudinfo/#google-cloud","title":"Google Cloud","text":""},{"location":"Knowledge/Cloud/cloudinfo/#others-public-cloud-providers","title":"Others Public Cloud Providers","text":""},{"location":"Knowledge/Cloud/cloudinfo/#cloud-connectors","title":"Cloud Connectors","text":""},{"location":"Knowledge/Cloud/Providers/digitalocean/","title":"DigitalOcean","text":""},{"location":"Knowledge/Cloud/Providers/linode/","title":"Linode","text":""},{"location":"Knowledge/Cloud/Providers/vultr/","title":"Vultr","text":""},{"location":"Knowledge/Databases/mariadb/","title":"MariaDB Cheat-Sheet","text":""},{"location":"Knowledge/Databases/mariadb/#install-mariadb-on-ubuntu-2004-lts","title":"Install MariaDB on Ubuntu 20.04 LTS","text":"<pre><code>sudo apt update\nsudo apt install mariadb-server\nsudo mysql_secure_installation\n</code></pre>"},{"location":"Knowledge/Databases/mariadb/#access-database-from-outside","title":"Access Database from outside","text":"<p>Open <code>/etc/mysql/mariadb.conf.d/50-server.cnf</code> and change the <code>bind-address</code> to: <pre><code>...\n\nbind-address = 0.0.0.0\n\n...\n</code></pre></p>"},{"location":"Knowledge/Databases/mariadb/#create-administrative-user","title":"Create Administrative User","text":"<ol> <li> <p>Create a new user <code>newuser</code> for the host <code>localhost</code> with a new <code>password</code>: <pre><code>CREATE USER 'newuser'@'localhost' IDENTIFIED BY 'password';\n</code></pre></p> </li> <li> <p>Grant all permissions to the new user <pre><code>GRANT ALL PRIVILEGES ON * . * TO 'newuser'@'localhost';\n</code></pre></p> </li> <li> <p>Update permissions <pre><code>FLUSH PRIVILEGES;\n</code></pre></p> </li> </ol>"},{"location":"Knowledge/Databases/postgres/","title":"PostgreSQL Cheat-Sheet","text":"<p>PostgreSQL or also known as Postgres, is a free and open-source relational database management system. PostgreSQL features transactions with Atomicity, Consistency, Isolation, Durability (ACID) properties automatically updatable views, materialized views, triggers, foreign keys, and stored procedures. It is designed to handle a range of workloads, from single machines to data warehouses or web services with many concurrent users.</p>"},{"location":"Knowledge/Databases/postgres/#installation","title":"Installation","text":""},{"location":"Knowledge/Databases/postgres/#install-postgresql-12-on-ubuntu-2004-lts","title":"Install PostgreSQL 12 on Ubuntu 20.04 LTS","text":"<pre><code>sudo apt update\nsudo apt install -y postgresql postgresql-contrib postgresql-client\nsudo systemctl status postgresql.service\n</code></pre>"},{"location":"Knowledge/Databases/postgres/#install-deploy-postgres-on-kubernetes-with-zalando-postgres-operator","title":"Install / deploy Postgres on Kubernetes with Zalando Postgres Operator","text":"<p>Postgres is probably the database which is most common on Cloud platforms and also, running on Kubernetes environments. There are several so called \"Kubernetes Operators\" which handle the deployment of Postgres clusters for you. One of it is the Postgres Operator by Zalando.</p> <p>You can find some tutorials regarding deployment of the operator and how to work with it, in the link list below:</p> <ul> <li>Deploy Zalando Postgres Operator on your Kubernetes cluster</li> <li>Configure Zalando Postgres Operator Backup with WAL-G</li> <li>Configure Zalando Postgres Operator Restore with WAL-G</li> </ul>"},{"location":"Knowledge/Databases/postgres/#initial-database-connection","title":"Initial database connection","text":"<p>A local connection (from the database server) can be done by the following command:</p> <pre><code>sudo -u postgres psql\n\npsql (12.12 (Ubuntu 12.12-0ubuntu0.20.04.1))\nType \"help\" for help.\n\npostgres=#\n</code></pre>"},{"location":"Knowledge/Databases/postgres/#set-password-for-postgres-database-user","title":"Set password for postgres database user","text":"<p>The password for the <code>postgres</code> database user can be set the the quickcommand <code>\\password</code> or by <code>alter user postgres password 'Supersecret'</code>. A connection using the <code>postgres</code> user is still not possible from the \"outside\" hence to the default settings in the <code>pg_hba.conf</code>.</p>"},{"location":"Knowledge/Databases/postgres/#update-pg_hbaconf-to-allow-postgres-user-connections-with-password","title":"Update pg_hba.conf to allow postgres user connections with password","text":"<p>In order to allow connections of the <code>postgres</code> database user not using OS user authentication, you have to update the <code>pg_hba.conf</code> which can be found under <code>/etc/postgresql/12/main/pg_hba.conf</code>.</p> <pre><code>sudo vi /etc/postgresql/12/main/pg_hba.conf\n\n...\nlocal   all             postgres                                peer\n...\n</code></pre> <p>Change the last section of the above line to <code>md5</code>.</p> <pre><code>local   all             postgres                                md5\n</code></pre> <p>A restart is required in order to apply the new configuration:</p> <pre><code>sudo systemctl restart postgresql\n</code></pre> <p>Now a connection from outside the database host is possible e.g.</p> <pre><code>psql -U postgres -d postgres -h databasehostname\n</code></pre>"},{"location":"Knowledge/Databases/postgres/#creation-of-additional-database-users","title":"Creation of additional database users","text":"<p>A database user can be created by the following command:</p> <pre><code>create user myuser with encrypted password 'Supersecret';\nCREATE ROLE\n\npostgres=# \\du\n                                   List of roles\n Role name |                         Attributes                         | Member of\n-----------+------------------------------------------------------------+-----------\n myuser    |                                                            | {}\n postgres  | Superuser, Create role, Create DB, Replication, Bypass RLS | {}\n</code></pre>"},{"location":"Knowledge/Databases/postgres/#creation-of-additional-databases","title":"Creation of additional databases","text":"<p>One can create new Postgres databases within an instance. Therefore you can use the <code>psql</code> command to login (see above).</p> <pre><code>CREATE DATABASE dbname OWNER myuser;\nCREATE DATABASE\n\npostgres=# \\l\n                                  List of databases\n   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges\n-----------+----------+----------+-------------+-------------+-----------------------\n dbname    | myuser   | UTF8     | en_US.UTF-8 | en_US.UTF-8 |\n postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |\n template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +\n           |          |          |             |             | postgres=CTc/postgres\n template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +\n           |          |          |             |             | postgres=CTc/postgres\n</code></pre> <p>You can leave the <code>OWNER</code> section of the command, when doing so, the current user will become owner of the newly created database.</p> <p>To change the owner of an existing database later, you can use the following command:</p> <pre><code>postgres=# alter database dbname owner to myuser;\nALTER DATABASE\n</code></pre>"},{"location":"Knowledge/Databases/postgres/#backup-and-restore","title":"Backup and Restore","text":"<p>There are near to endless combinations in tools and parameters to backup postgres databases. Below you can find some examples using the Postgres built-in tools <code>pgdump</code>, <code>pg_basebackup</code> and <code>pg_restore</code>.</p>"},{"location":"Knowledge/Databases/postgres/#pg_dump-pg_dumpall","title":"pg_dump / pg_dumpall","text":"<p>Using <code>pg_dump</code> or <code>pg_dumpall</code> enables you to extract / export a PostgreSQL database(s) into a (SQL) script file or a custom archive file.</p>"},{"location":"Knowledge/Databases/postgres/#pg_dump","title":"pg_dump","text":"<p>The following command creates a custom archive file from a database specified with <code>-d</code>.  Using the <code>--create</code> option will include the SQL commands in the dump script that will create the database before importing it later. The <code>-Z 9</code> option in this example compresses the SQL script created with the highest available compression rate (<code>0-9</code>).</p> <pre><code>pg_dump -h vmdocker -U awx -d awx --create -f -Z 9 /tmp/awx_dump.sql.gz\n</code></pre> <p>The following command creates a custom archive file from a database specified with <code>-d</code>. To export data in custom format, you have to specify so with the <code>-F c</code> option. Custom file dumps have the benefit, that they are compressed by default.</p> <pre><code>pg_dump -h &lt;pg_host&gt; -U &lt;username&gt; -d &lt;database&gt; -F c -f /pg_dump/dumpfile.dmp\n</code></pre> <p>Custom format files can only be restored by <code>pg_restore</code> (see below). A SQL dump can be restored by using <code>psql</code>.</p> <pre><code>psql -d newdb -f db.sql\n</code></pre> <p>A complete guide of <code>pg_dump</code> from the official documentation can be found here.</p>"},{"location":"Knowledge/Databases/postgres/#pg_dumpall","title":"pg_dumpall","text":"<p>A full dump of all databases of a Postgres instance can be done by <code>pg_dumpall</code>. It will include also user creation information. A difference to <code>pg_dump</code>, you cannot choose for different output formats. <code>pg_dumpall</code> will always create a SQL script as output. Therefore, you don't need <code>pg_restore</code> for restoring a \"full\" dump. Only <code>psql</code> is needed (see below).</p> <pre><code>pg_dumpall -h &lt;pg_host&gt; -U postgres &gt; database.out\n</code></pre> <p>If you use password authentication it will ask for a password each time. It is convenient to have a <code>~/.pgpass</code> file or <code>PGPASSWORD</code> environment variable set.</p> <p>So importing a full dump is really easy by the following <code>psql</code> command:</p> <pre><code>psql -h &lt;pg_host&gt; -f databaseb.out -U postgres\n</code></pre> <p>A complete guide of <code>pg_dumpall</code> from the official documentation can be found here.</p>"},{"location":"Knowledge/Databases/postgres/#pg_restore","title":"pg_restore","text":"<p><code>pg_restore</code> can be used to restore custom file dumps created by <code>pg_dump</code>.</p> <p>The following command will create the database (which has been dumped before). <pre><code>pg_restore -h &lt;pg_host&gt; -U &lt;pg_user&gt; -d postgres --create -F c /tmp/db.dmp -v\n</code></pre></p> <p>A complete guide of <code>pg_restore</code> from the official documentation can be found here.</p>"},{"location":"Knowledge/Docker/docker-compose/","title":"Docker-Compose","text":"<p>...</p>"},{"location":"Knowledge/Docker/docker-compose/#networking","title":"Networking","text":"<p>By default Docker-Compose will create a new network for the given compose file. You can change the behavior by defining custom networks in your compose file.</p>"},{"location":"Knowledge/Docker/docker-compose/#create-and-assign-custom-network","title":"Create and assign custom network","text":"<p>... Example: <pre><code>networks:\n  custom-network:\n\nservices:\n  app:\n    networks:\n      - custom-network\n</code></pre></p>"},{"location":"Knowledge/Docker/docker-compose/#use-existing-networks","title":"Use existing networks","text":"<p>If you want to use an existing Docker network for your compose files, you can add the <code>external: true</code> parameter in your compose file Example: <pre><code>networks:\n  existing-network:\n    external: true\n</code></pre></p>"},{"location":"Knowledge/Docker/docker-compose/#volumes","title":"Volumes","text":"<p>Volumes allow Docker containers to use persistent storage. In a compose file, you can create and map volumes like this: <pre><code>volumes:\n  my-volume:\n\nservices:\n  app:\n    volumes:\n      - my-volume:/path-in-container\n</code></pre></p> <p>These volumes are stored in <code>/var/lib/docker/volumes</code>.</p>"},{"location":"Knowledge/Docker/docker/","title":"Docker","text":"<p>Docker\u00a0is a set of\u00a0platform as a service\u00a0(PaaS) products that use\u00a0OS-level virtualization\u00a0to deliver software in packages called\u00a0containers. The service has both free and premium tiers. The software that hosts the containers is called\u00a0Docker Engine.</p> <p>Project Homepage: Home - Docker Documentation: Docker Documentation | Docker Documentation</p>"},{"location":"Knowledge/Docker/docker/#installation","title":"Installation","text":"<p>One click installation script: <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n</code></pre></p> <p>Run docker as non root user: <pre><code>sudo groupadd docker\nsudo usermod -aG docker $USER\n</code></pre></p> <p>Install Docker Engine : Docker Engine</p>"},{"location":"Knowledge/Docker/docker/#build-images","title":"Build Images","text":""},{"location":"Knowledge/Docker/docker/#docker-cli","title":"Docker CLI","text":"<p>Run Containers</p> COMMAND DESCRIPTION <code>docker run IMAGE</code> Start a new container <code>docker run --name CONTAINER IMAGE</code> Start a new container and set a name <code>docker run -p HOSTPORT:CONTAINERPORT IMAGE</code> Start a new container with mapped ports <code>docker run -P IMAGE</code> Start a new container and map all ports <p>Container Management:</p> COMMAND DESCRIPTION <code>docker create IMAGE</code> Create a new container <code>docker start CONTAINER</code> Start a container <code>docker stop CONTAINER</code> Graceful stop a container <code>docker kill CONTAINER</code> Kill (SIGKILL) a container <code>docker restart CONTAINER</code> Graceful stop and restart a container <code>docker pause CONTAINER</code> Suspend a container <code>docker unpause CONTAINER</code> Resume a container <code>docker rm CONTAINER</code> Destroy a container <p>Container Bulk Management</p> COMMAND DESCRIPTION <code>docker stop $(docker ps -q)</code> To stop all the running containers <code>docker stop $(docker ps -a -q)</code> To stop all the stopped and running containers <code>docker kill $(docker ps -q)</code> To kill all the running containers <code>docker kill $(docker ps -a -q)</code> To kill all the stopped and running containers <code>docker restart $(docker ps  -q)</code> To restart all  running containers <code>docker restart $(docker ps -a -q)</code> To restart all the stopped and running containers <code>docker rm $(docker ps  -q)</code> To destroy all running containers <code>docker rm $(docker ps -a -q)</code> To destroy all the stopped and running containers <code>docker pause $(docker ps  -q)</code> To pause all  running containers <code>docker pause $(docker ps -a -q)</code> To pause all the stopped and running containers <code>docker start $(docker ps  -q)</code> To start all  running containers <code>docker start $(docker ps -a -q)</code> To start all the stopped and running containers <code>docker rm -vf $(docker ps -a -q)</code> To delete all containers including its volumes use <code>docker rmi -f $(docker images -a -q)</code> To delete all the images <code>docker system prune</code> To delete all dangling and unused images, containers, cache and volumes <code>docker system prune -a</code> To delete all used and unused images <code>docker system prune --volumes</code> To delete all docker volumes <p>Inspect Containers:</p> COMMAND DESCRIPTION <code>docker ps</code> List running containers <code>docker ps -a</code> List all containers, including stopped <code>docker logs CONTAINER</code> Show a container output <code>docker logs -f CONTAINER</code> Follow a container output <code>docker top CONTAINER</code> List the processes running in a container <code>docker diff</code> Show the differences with the image (modified files) <code>docker inspect</code> Show information of a container (json formatted) <p>Run Commands:</p> COMMAND DESCRIPTION <code>docker attach CONTAINER</code> Attach to a container <code>docker cp CONTAINER:PATH HOSTPATH</code> Copy files from the container <code>docker cp HOSTPATH CONTAINER:PATH</code> Copy files into the container <code>docker export CONTAINER</code> Export the content of the container (tar archive) <code>docker exec CONTAINER</code> Run a command inside a container <code>docker exec -it CONTAINER /bin/bash</code> Open an interactive shell inside a container (there is no bash in some images, use /bin/sh) <code>docker wait CONTAINER</code> Wait until the container terminates and return the exit code <p>Images:</p> COMMAND DESCRIPTION <code>docker images</code> List all local images <code>docker history IMAGE</code> Show the image history <code>docker inspect IMAGE</code> Show information (json formatted) <code>docker tag IMAGE TAG</code> Tag an image <code>docker commit CONTAINER IMAGE</code> Create an image (from a container) <code>docker import URL</code> Create an image (from a tarball) <code>docker rmi IMAGE</code> Delete images <code>docker pull REPO:[TAG]</code> pull an image/repo from a registry <code>docker push REPO:[TAG]</code> push and image/repo to a registry <code>docker search TEXT</code> Search an image on the official registry <code>docker login</code> Login to a registry <code>docker logout</code> Logout from a registry <code>docker save REPO:[TAG]</code> Export an image/repo as a tarball <code>docker load</code> Load images from a tarball <p>Volumes:</p> COMMAND DESCRIPTION <code>docker volume ls</code> List all vol1umes <code>docker volume create VOLUME</code> Create a volume <code>docker volume inspect VOLUME</code> Show information (json formatted) <code>docker volume rm VOLUME</code> Destroy a volume <code>docker volume ls --filter=\"dangling=true\"</code> List all dangling volumes (not referenced by any container) <code>docker volume prune</code> Delete all volumes (not referenced by any container)"},{"location":"Knowledge/Docker/docker/#backup-a-container","title":"Backup a container","text":"<p>Backup docker data from inside container volumes and package it in a tarball archive. <code>docker run --rm --volumes-from CONTAINER -v $(pwd):/backup busybox tar cvfz /backup/backup.tar CONTAINERPATH</code></p> <p>An automated backup can be done also by this Ansible playbook. The output is also a (compressed) tar. The playbook can also manage the backup retention. So older backups will get deleted automatically.</p> <p>To also create and backup the container configuration itself, you can use <code>docker-replay</code>for that. If you lose the entire container, you can recreate it with the export from <code>docker-replay</code>. A more detailed tutorial on how to use docker-replay can be found here.</p>"},{"location":"Knowledge/Docker/docker/#restore-container-from-backup","title":"Restore container from backup","text":"<p>Restore the volume with a tarball archive. <code>docker run --rm --volumes-from CONTAINER -v $(pwd):/backup busybox sh -c \"cd CONTAINERPATH &amp;&amp; tar xvf /backup/backup.tar --strip 1\"</code></p>"},{"location":"Knowledge/Docker/docker/#networks","title":"Networks","text":""},{"location":"Knowledge/Docker/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Knowledge/Docker/docker/#networking","title":"Networking","text":"<p><code>docker run --name netshoot --rm -it nicolaka/netshoot /bin/bash</code></p>"}]}